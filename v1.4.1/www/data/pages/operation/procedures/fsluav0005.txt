====== Lustre, Añadir OST en caliente ======

===== Datos Generales =====


|< 50% >|
^  Código       ^  Nombre Procedimiento   ^  Verificado    ^  Operativo    ^  Fecha Creación   ^  Fecha Ultima Modificación  ^  Versión  ^
|  FSLUAV0005   |  Añadir OST en caliente  |  @#FA5858:<fc white>NO</fc>   |  @#FA5858:<fc white>NO</fc>  |  03/02/2016       |  03/02/2016                 |    0.0    | 


  * ** <fc red> IMPORTANTE: </fc> INFORMACION DEL ENTORNO : ** {{popup>:documentation:cyclops:architecture?[keepOpen]|AEMET: HPC Architecture and Risk Definitions}}

===== Sistemas Objetivo =====

|< 100% 10% 10% 32% 8% 30% >|  
^  Grupo Lustre     ^  Nodos                      ^  Descripción                                                                             ^  Criticidad          ^  Implicación  ^
|  Lustre OSS/MDS  |  nimbus[6-9]  | Añadir espacio a un sistema de ficheros lustre                                                      |  <fc white>@#FA5858:ALTA</fc>      |               |

===== Sistemas Colaterales =====

|< 100% 10% 10% 32% 8% 30% >| 
^  Grupo         ^  Nodos           ^  Descripción                                                     ^  Criticidad  ^  Implicación  ^ 
|  Gestión       |  nimbus[0-1]     |  Permiten la administración del servicio                         |  @#EAFFD5: BAJA      |  Los Administradores no pueden acceder directamente a lustre  |
|  Lustre        |  nimbus[6-9]     |  Funcionamiento del servicio                                     |  @#FA5858: <fc white>MUY ALTA</fc>  |  Posibilidad de caída completa del sistema productivo    |
|  Login         |  nimbus[2-3]     |  Acceso de los usuarios al sistema productivo                    |  @#FA5858: <fc white>MUY ALTA</fc>  |  Posibilidad de caída completa del sistema productivo   |
|  Computo/Aire  |  nimbus[10-13]   |  Uso del servicio por el sistema productivo                      |  @#FA5858: <fc white>MUY ALTA</fc>     |  Posibilidad de caída completa del sistema productivo  |
|  DEV           |  nimbus[4-5]     |  Acceso de los usuarios de desarrollo                            |  @#FFFF00: MEDIA     |  Posibilidad de caída completa del entrono de desarrollo  |
|  Computo/Agua  |  nimbus[0-9]{4}  |  Uso del servicio por el sistema productivo                      |  @#FFFF00: MEDIA     |  Posibilidad de caída completa del entrono de desarrollo  |




===== Procedimiento =====

==== Descripción ====
 
** <fc red>NOTA:</fc> PROCEDIMIENTO __ÚNICAMENTE__ PARA ADMINISTRADORES DEL SISTEMA ** 

  * Procedimiento para añadir OSTs sin interrupción:

Gauthier Delerce (Bull Support Technician):

>> //I created the two filesystems and configured HA ; I will now start few HA tests ( basically, kill each servers during client IO and check if everything is fine).
Below my notes to add clients and OST to a filesystem with no interrupts.
I will contact you again after the test, please read the notes and tell me if you need something else.//

==== Alcance ====

  * ** Este procedimiento solo se ejecutara por los siguientes actores en las siguientes circunstancias: **

|< 50% >|
^  ACTOR          ^  EJECUCION                   ^  HORARIO EJECUCION                                                ^
|  AEMET          |  @#FA5858:<fc white>NO</fc>  |  NINGUNO                                                          |
|  BULL VALENCIA  |  @#FA5858:<fc white>NO</fc>  |  NINGUNO                                                          |
|  BULL AEMET     |  @#EAFFD5:SI                 |  @#EAFFD5:HORARIO ( L-J 08:00-17:30 y V 08:00-14:00 HORA LOCAL )  |
|  BULL MADRID    |  @#FA5858:<fc white>NO</fc>  |  NINGUNO                                |
==== Paso 1 ====

  * List of free OST :<code>
lustre_target_dba list --type ost --free
</code>

<hidden Command Output>
<code>

Type - Name                  - Data device     - Size - Journal device - Size - Rank - Master  - Active  - HA              - NID   - Suffix - FS
ost  - ost_nimbus8ldn.da1.d2 - /dev/ldn.da1.d2 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib0 - ib0    -
ost  - ost_nimbus9ldn.da2.d3 - /dev/ldn.da2.d3 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib0 - ib0    -
ost  - ost_nimbus8ldn.da2.d4 - /dev/ldn.da2.d4 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib0 - ib0    -
ost  - ost_nimbus9ldn.da2.d5 - /dev/ldn.da2.d5 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib0 - ib0    -
ost  - ost_nimbus8ldn.da3.d0 - /dev/ldn.da3.d0 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib0 - ib0    -
ost  - ost_nimbus9ldn.da3.d1 - /dev/ldn.da3.d1 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib0 - ib0    -
ost  - ost_nimbus8ldn.da3.d2 - /dev/ldn.da3.d2 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib0 - ib0    -
ost  - ost_nimbus9ldn.da4.d3 - /dev/ldn.da4.d3 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib0 - ib0    -
ost  - ost_nimbus8ldn.da4.d4 - /dev/ldn.da4.d4 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib0 - ib0    -
ost  - ost_nimbus9ldn.da4.d5 - /dev/ldn.da4.d5 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib0 - ib0    -
ost  - ost_nimbus9ldn.da1.d5 - /dev/ldn.da1.d5 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib1 - ib1:0  -
ost  - ost_nimbus9ldn.da2.d1 - /dev/ldn.da2.d1 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib1 - ib1:0  -
ost  - ost_nimbus8ldn.da2.d2 - /dev/ldn.da2.d2 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib1 - ib1:0  -
ost  - ost_nimbus9ldn.da3.d3 - /dev/ldn.da3.d3 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib1 - ib1:0  -
ost  - ost_nimbus8ldn.da3.d4 - /dev/ldn.da3.d4 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib1 - ib1:0  -
ost  - ost_nimbus9ldn.da3.d5 - /dev/ldn.da3.d5 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib1 - ib1:0  -
ost  - ost_nimbus8ldn.da4.d0 - /dev/ldn.da4.d0 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib1 - ib1:0  -
ost  - ost_nimbus9ldn.da4.d1 - /dev/ldn.da4.d1 - -1   -                -      - 0    - nimbus9 - nimbus9 - nimbus9,nimbus8 - o2ib1 - ib1:0  -
ost  - ost_nimbus8ldn.da4.d2 - /dev/ldn.da4.d2 - -1   -                -      - 0    - nimbus8 - nimbus8 - nimbus8,nimbus9 - o2ib1 - ib1:0  -
</code>
</hidden>

==== Paso 2 ====


  * add 1 ost **Ej:**//( ost_nimbus8ldn.da3.d0 ) to a filesystem ( scratch1 )// ** edit /etc/shine/models/scratch01.lmf ** and add in ost section //ost: tag=ost_nimbus8ldn.da3.d0//
  * Then update the filesystem with the modified model :<code>
hashine updatefs -f scratch1 -m /etc/shine/models/scratch01.lmf</code>

<hidden Command Output:>
<code>
Running command:
shine update -m /etc/shine/models/scratch01.lmf -y

========================================
BEGINNING OF SHINE OUTPUT
========================================

Using Lustre model file /etc/shine/models/scratch01.lmf
FILESYSTEM CHANGES
* Format: 1 component(s) on nimbus8
* Start: 1 component(s) on nimbus8
* Will not be done automatically

Register target(s) scratch1-OST0003 into backend.
Update configuration file: /var/cache/shine/conf/scratch1.xmf
Updating configuration file `scratch1.xmf' on 40 server(s)
Configuration file successfully updated.
Update configuration file: /etc/shine/tuning.conf
Updating configuration file `tuning.conf' on 40 server(s)
Configuration file successfully updated.

NEXT ACTIONS (should be done manually)
>You can now `format' 1 new target(s)
>  shine format -f scratch1 -l scratch1-OST0003
>You can now `start' 1 new component(s)
>  shine start -f scratch1 -l scratch1-OST0003
Update is finished.

========================================
END OF SHINE OUTPUT
========================================
</code>
</hidden>

==== Paso 3 ====

  * The following commands must now be run in order to complete the update:<code>
shine format -f scratch1 -l scratch1-OST0003</code>
  * Next:<code>
clush -bw nimbus[8-9] tune-storage-device</code>
  * <fc red> ** Next: ** </fc><code>
shine start -f scratch2 -l scratch1-OST0003</code>
  * Next:<code>
hashine addfs -f scratch1 --hot --force</code>
  * Next:<code>
hashine startfs -f scratch1
</code>
  * <fc red> ** Then just execute the commands :** </fc><code>
[root@nimbus0 models]# shine format -f scratch1 -l scratch1-OST0003</code>

<hidden Command Output>
<code>
Format scratch1 on nimbus8: are you sure? (y)es/(N)o: y
[12:55] In progress for 1 component(s) on nimbus8 ...
Format successful.
= FILESYSTEM STATUS (scratch1) =
TYPE # STATUS  NODES
---- - ------  -----
OST  2 offline nimbus8
</code>
</hidden>

  * <fc red> **Next:** </fc><code>
clush -bw nimbus[8-9] tune-storage-device
</code>
  * <fc red> **Next:** </fc><code>
shine start -f scratch1 -l scratch1-OST0003</code>

<hidden Command Output>
<code>
Updating configuration file `tuning.conf' on nimbus[8-9]
Start successful.
= FILESYSTEM STATUS (scratch1) =
TYPE # STATUS NODES
---- - ------ -----
OST  1 online nimbus8
</code>
</hidden>

  * <fc red> **Next:** </fc><code>
hashine addfs -f scratch1 --hot --force</code>

<hidden Command Output>
<code>
WARNING: Adding only the following targets:
        ost_nimbus8ldn.da3.d0
WARNING: adding the following targets in hot mode (they will be automatically HA started):
        ost_nimbus8ldn.da3.d0 on nimbus8
WARNING: Acting only on the following targets:
        ost_nimbus8ldn.da3.d0
0 MGT target(s) to start
1 OST target(s) to start
All OST targets started
0 MDT target(s) to start
Status for fs : scratch1
+-----------------------+---------+---------+--------------+-------------------------+
|                       | Status  |  Node   | Configured ? |    Migration status     |
+-----------------------+---------+---------+--------------+-------------------------+
| mdt_nimbus6ldn.da5.d1 | Started | nimbus6 | Yes          | Running on primary node |
| ost_nimbus8ldn.da1.d0 | Started | nimbus8 | Yes          | Running on primary node |
| ost_nimbus8ldn.da2.d0 | Started | nimbus8 | Yes          | Running on primary node |
| ost_nimbus8ldn.da3.d0 | Started | nimbus8 | Yes          | Running on primary node |
| ost_nimbus9ldn.da1.d3 | Started | nimbus9 | Yes          | Running on primary node |
+-----------------------+---------+---------+--------------+-------------------------+
</code>
</hidden>

  * <fc red> **Next:** </fc><code>
hashine startfs -f scratch1</code>

<hidden Command Output>
<code>
0 MGT target(s) to start
0 OST target(s) to start
0 MDT target(s) to start
Status for fs : scratch1
+-----------------------+---------+---------+--------------+-------------------------+
|                       | Status  |  Node   | Configured ? |    Migration status     |
+-----------------------+---------+---------+--------------+-------------------------+
| mdt_nimbus6ldn.da5.d1 | Started | nimbus6 | Yes          | Running on primary node |
| ost_nimbus8ldn.da1.d0 | Started | nimbus8 | Yes          | Running on primary node |
| ost_nimbus8ldn.da2.d0 | Started | nimbus8 | Yes          | Running on primary node |
| ost_nimbus8ldn.da3.d0 | Started | nimbus8 | Yes          | Running on primary node |
| ost_nimbus9ldn.da1.d3 | Started | nimbus9 | Yes          | Running on primary node |
+-----------------------+---------+---------+--------------+-------------------------+
</code>
</hidden>

  * Now the filesystem has been extended with a ost:<code>
lfs df</code>

<hidden Command Output>
<code>
UUID                   1K-blocks        Used   Available Use% Mounted on
scratch1-MDT0000_UUID  1754308456       91784  1754216672   0% /SCRATCH01[MDT:0]
scratch1-OST0000_UUID 15614828100     7013476 15607471584   0% /SCRATCH01[OST:0]
scratch1-OST0001_UUID 15614828100     7350372 15607448032   0% /SCRATCH01[OST:1]
scratch1-OST0002_UUID 15614828100     4204632 15610621148   0% /SCRATCH01[OST:2]
scratch1-OST0003_UUID 15614828100       10316 15614817784   0% /SCRATCH01[OST:3]

filesystem summary:  62459312400    18578796 62440358548   0% /SCRATCH01
</code>
</hidden>

Gauthier Delerce:
>> ** //The ost are not balanced because the fs has been created with scratch1-OST0000_UUID and scratch1-OST0000_UUID ; then I added scratch1-OST0002_UUID; and few minutes later scratch1-OST0003_UUID. Because a client was doing continuous writing, ( no error reported ), the space used on each OST is different. // **

==== Paso 4 ====

  * <fc red> **To add client :**</fc><code>
hashine updatefs -f scratch2 -m /etc/shine/models/scratch02.lmf
</code>
  * Next:<code>
shine update -m /etc/shine/models/scratch02.lmf -y</code>

<hidden Command output:>
<code>
========================================
BEGINNING OF SHINE OUTPUT
========================================

Using Lustre model file /etc/shine/models/scratch02.lmf
FILESYSTEM CHANGES
* Mount: 18 component(s) on nimbus[3201-3218]
* Will not be done automatically

Update configuration file: /var/cache/shine/conf/scratch2.xmf
Updating configuration file `scratch2.xmf' on 40 server(s)
Configuration file successfully updated.
Update configuration file: /etc/shine/tuning.conf
Updating configuration file `tuning.conf' on 40 server(s)
Configuration file successfully updated.

NEXT ACTIONS (should be done manually)

You can now `mount' the needed 18 client(s)
shine mount -f scratch2 -n nimbus[3201-3218]

Update is finished.

========================================
END OF SHINE OUTPUT
========================================
</code>
</hidden>



==== Paso 5 ====

  * The following commands must now be run in order to complete the update:<code>
shine mount -f scratch2 -n nimbus[3201-3218]</code>

<hidden Command Output>
<code>
shine mount -f scratch2 -n nimbus[3201-3218]
Updating configuration file `tuning.conf' on 18 server(s)
scratch2 was successfully mounted on nimbus[3201-3218]
= FILESYSTEM STATUS (scratch2) =
TYPE  # STATUS  NODES
----  - ------  -----
CLI  18 mounted nimbus[3201-3218]
</code>
</hidden>